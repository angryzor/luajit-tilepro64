# Config file for ReBench
# Config format is YAML (see http://yaml.org/ for detailed spec)

# this run definition will be choosen if no parameters are given to rebench
standard_run: tilera
standard_dataFile: 'rebench.data'

# reporting should enable the configuration of the format of the out put
# REM: not implement yet (STEFAN: 2011-01-19)
reporting:
    csv_file: rebench.csv
    csv_locale: de_DE.UTF-8
    csv_raw: rebench.data.csv

# settings and requirements for statistic evaluation
statistics:
    min_runs: 1
    max_runs: 3
    confidence_level: 0.90
    error_margin: 0.005
    stop_criterium: percentage
    stop_threshold: 5
 
# settings for quick runs, useful for fast feedback during experiments
quick_runs:
    min_runs: 3
    max_runs: 10
    max_time: 60   # time in seconds

# definition of benchmark suites
benchmark_suites:
    tilera:
        performance_reader: TimeManualPerformance
        command: "%(benchmark)s " # %(input)s "
        input_sizes: [1]
        ulimit: 600
        benchmarks:
            # Computer Language Benchmarks Game
##            - BenchmarkGameSuite.benchFasta:
##                extra_args: "2000"
##            - benchmarks/ackermann.lua-2.lua:
##                extra_args: "12"
#            - benchmarks/ary.lua:
#                extra_args: "12"
#            - benchmarks/binarytrees.lua-2.lua:
#                extra_args: "12"
            - benchmarks/binarytrees.lua-3.lua:
                extra_args: "12"
#            - benchmarks/chameneos.lua:
#                extra_args: "12"
#            - benchmarks/disabled:
#                extra_args: "12"
#            - benchmarks/except.lua:
#                extra_args: "12"
#            - benchmarks/fannkuch.lua:
#                extra_args: ""
#            - benchmarks/fannkuch.lua-2.lua:
#                extra_args: ""
#            - benchmarks/fannkuchredux.lua:
#                extra_args: ""
#            - benchmarks/fasta.lua:
#                extra_args: "2000"
#            - benchmarks/fibo.lua:
#                extra_args: "12"
#            - benchmarks/harmonic.lua:
#                extra_args: ""
#            - benchmarks/hash2.lua:
#                extra_args: "12"
#            - benchmarks/hash.lua:
#                extra_args: "12"
#            - benchmarks/hello.lua:
#                extra_args: "12"
#            - benchmarks/lists.lua:
#                extra_args: "12"
#            - benchmarks/mandelbrot.lua:
#                extra_args: ""
#            - benchmarks/mandelbrot.lua-2.lua:
#                extra_args: ""
#            - benchmarks/matrix.lua:
#                extra_args: "12"
#            - benchmarks/message.lua-2.lua:
#                extra_args: "12"
#            - benchmarks/moments.lua:
#                extra_args: "12"
#            - benchmarks/nbody.lua:
#                extra_args: "2000"
#            - benchmarks/nbody.lua-2.lua:
#                extra_args: "2000"
#            - benchmarks/nbody.lua-4.lua:
#                extra_args: "2000"
#            - benchmarks/nestedloop.lua:
#                extra_args: "12"
#            - benchmarks/nsievebits.lua:
#                extra_args: ""
#            - benchmarks/nsieve.lua-3.lua:
#                extra_args: "3"
#            - benchmarks/partialsums.lua-2.lua:
#                extra_args: "12"
#            - benchmarks/partialsums.lua-3.lua:
#                extra_args: "12"
#            - benchmarks/process.lua:
#                extra_args: "2000"
#            - benchmarks/prodcons.lua:
#                extra_args: "12"
#            - benchmarks/random.lua:
#                extra_args: "12"
#            - benchmarks/recursive.lua:
#                extra_args: "3"
#            - benchmarks/regexdna.lua:
#                extra_args: "12"
#            - benchmarks/regexmatch.lua:
#                extra_args: "12"
#            - benchmarks/reversefile.lua:
#                extra_args: "12"
#            - benchmarks/sieve.lua:
#                extra_args: "12"
#            - benchmarks/sieve.lua-2.lua:
#                extra_args: "12"
#            - benchmarks/spectralnorm.lua:
#                extra_args: "500"
#            - benchmarks/spellcheck.lua:
#                extra_args: "12"
#            - benchmarks/strcat.lua:
#                extra_args: "12"
#            - benchmarks/strcat.lua-2.lua:
#                extra_args: "12"
#            - benchmarks/sumcol.lua:
#                extra_args: "12"
#            - benchmarks/takfp.lua:
#                extra_args: ""
#            - benchmarks/wc.lua:
#                extra_args: "12"
#            - benchmarks/wordfreq.lua:
#                extra_args: "12"
 
# VMs have a name and are specified by a path and the binary to be executed
virtual_machines:
    luajit:
        path: .
        binary: run-luajit
        args: ""
        cores: [1]
    lua:
        path: .
        binary: run-lua
        args: ""
        cores: [1]



# define the benchmarks to be executed for a re-executable benchmark run
run_definitions:
    tilera:
        description: >
            Standard tests to check for performance regressions
        actions: benchmark
        benchmark: tilera
        executions:
            - luajit
            - lua

